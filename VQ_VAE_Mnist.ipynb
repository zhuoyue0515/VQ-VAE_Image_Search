{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VQ-VAE_Mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc6SV1l7yMJH",
        "colab_type": "code",
        "outputId": "26008c3b-db5d-4135-fa7c-8969a79450e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!pip install -U dm-sonnet==1.23"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dm-sonnet==1.23\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/c7/e32a7d83724f26e921dcdd7ddd8f30e6e92cb4e68c740960307616b6ada8/dm_sonnet-1.23-py3-none-any.whl (616kB)\n",
            "\u001b[K    100% |████████████████████████████████| 624kB 21.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from dm-sonnet==1.23) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.6/dist-packages (from dm-sonnet==1.23) (0.6.1)\n",
            "Installing collected packages: dm-sonnet\n",
            "Successfully installed dm-sonnet-1.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSXdKPQeyQsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import tempfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sonnet as snt\n",
        "import tensorflow as tf\n",
        "import tarfile\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from six.moves import cPickle\n",
        "from six.moves import urllib\n",
        "from six.moves import xrange"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyBgOnDRofLh",
        "colab_type": "code",
        "outputId": "36413b69-6571-437b-b92d-0bf8b48be48a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train = np.resize(x_train, (60000,28,28,1))\n",
        "x_test = np.resize(x_test, (10000,28,28,1))\n",
        "train_dict = { \"images\": x_train, \"labels\":y_train}\n",
        "test_dict = { \"images\": x_test, \"labels\":y_test}\n",
        "def cast_and_normalise_images(data_dict):\n",
        " #Convert images to floating point with the range [-0.5, 0.5]\n",
        "    images = data_dict['images']\n",
        "    data_dict['images'] = (tf.cast(images, tf.float32) / 255.0) - 0.5\n",
        "    return data_dict\n",
        "data_variance = np.var(train_dict['images'] / 255.0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv7KbuDjzvkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def residual_stack(h, num_hiddens, num_residual_layers, num_residual_hiddens):\n",
        "    for i in range(num_residual_layers):\n",
        "        h_i = tf.nn.relu(h)\n",
        "\n",
        "        h_i = snt.Conv2D(\n",
        "            output_channels=num_residual_hiddens,\n",
        "            kernel_shape=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            name=\"res3x3_%d\" % i)(h_i)\n",
        "        h_i = tf.nn.relu(h_i)\n",
        "\n",
        "        h_i = snt.Conv2D(\n",
        "            output_channels=num_hiddens,\n",
        "            kernel_shape=(1, 1),\n",
        "            stride=(1, 1),\n",
        "            name=\"res1x1_%d\" % i)(h_i)\n",
        "        h += h_i\n",
        "    return tf.nn.relu(h)\n",
        "\n",
        "class Encoder(snt.AbstractModule):\n",
        "    def __init__(self, num_hiddens, num_residual_layers, num_residual_hiddens,\n",
        "               name='encoder'):\n",
        "        super(Encoder, self).__init__(name=name)\n",
        "        self._num_hiddens = num_hiddens\n",
        "        self._num_residual_layers = num_residual_layers\n",
        "        self._num_residual_hiddens = num_residual_hiddens\n",
        "    def _build(self, x):\n",
        "        h = snt.Conv2D(\n",
        "            output_channels=self._num_hiddens / 2,\n",
        "            kernel_shape=(4, 4),\n",
        "            stride=(2, 2),\n",
        "            name=\"enc_1\")(x) # (?, 16, 16, 64)\n",
        "        h = tf.nn.relu(h)\n",
        "\n",
        "        h = snt.Conv2D(\n",
        "            output_channels=self._num_hiddens,\n",
        "            kernel_shape=(4, 4), # (?, 8, 8, 128)\n",
        "            stride=(2, 2),\n",
        "            name=\"enc_4\")(h)\n",
        "        h = tf.nn.relu(h)\n",
        "#         h = tf.layers.conv2d(inputs=h, filters=self._num_hiddens, kernel_size=[4,4], strides=[3,3], padding=\"valid\", activation=tf.nn.relu)\n",
        "        h = snt.Conv2D(\n",
        "            output_channels=self._num_hiddens,\n",
        "            kernel_shape=(3, 3), # (?, 8, 8, 128)\n",
        "            stride=(1, 1),\n",
        "            name=\"enc_5\")(h)\n",
        "        \n",
        "        h = residual_stack(\n",
        "            h,\n",
        "            self._num_hiddens,\n",
        "            self._num_residual_layers,\n",
        "            self._num_residual_hiddens)\n",
        "        return h # (?, 8, 8, 128)\n",
        "\n",
        "class Decoder(snt.AbstractModule):\n",
        "    def __init__(self, num_hiddens, num_residual_layers, num_residual_hiddens,\n",
        "                   name='decoder'):\n",
        "        super(Decoder, self).__init__(name=name)\n",
        "        self._num_hiddens = num_hiddens\n",
        "        self._num_residual_layers = num_residual_layers\n",
        "        self._num_residual_hiddens = num_residual_hiddens\n",
        "    def _build(self, x):\n",
        "        h = snt.Conv2D(\n",
        "          output_channels=self._num_hiddens,\n",
        "          kernel_shape=(3, 3),\n",
        "          stride=(1, 1),\n",
        "          name=\"dec_1\")(x) # (?, 8, 8, 128)\n",
        "\n",
        "        h = residual_stack(\n",
        "            h,\n",
        "            self._num_hiddens,\n",
        "            self._num_residual_layers,\n",
        "            self._num_residual_hiddens) # (?, 8, 8, 128)\n",
        "        \n",
        "#         h = tf.layers.conv2d_transpose(inputs=h, filters=self._num_hiddens, kernel_size=[4,4], strides=[3,3], padding=\"valid\", activation=tf.nn.relu)\n",
        "        h = snt.Conv2DTranspose(\n",
        "            output_channels=int(self._num_hiddens / 2),\n",
        "            output_shape=None,\n",
        "            kernel_shape=(4, 4),\n",
        "            stride=(2, 2),\n",
        "            name=\"dec_4\")(h)\n",
        "        h = tf.nn.relu(h)\n",
        "        \n",
        "        x_recon = snt.Conv2DTranspose(\n",
        "            output_channels=1,\n",
        "        output_shape=None,\n",
        "        kernel_shape=(4, 4),\n",
        "        stride=(2, 2),\n",
        "        name=\"dec_5\")(h) # (?, 32, 32, 3)\n",
        "        return x_recon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tLXi6ucGxaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# Set hyper-parameters.\n",
        "batch_size = 32\n",
        "image_size = 28\n",
        "\n",
        "# 100k steps should take < 30 minutes on a modern (>= 2017) GPU.\n",
        "num_training_updates = 40000\n",
        "\n",
        "num_hiddens = 64\n",
        "num_residual_hiddens = 32\n",
        "num_residual_layers = 2\n",
        "# These hyper-parameters define the size of the model (number of parameters and layers).\n",
        "# The hyper-parameters in the paper were (For ImageNet):\n",
        "# batch_size = 128\n",
        "# image_size = 128\n",
        "# num_hiddens = 128\n",
        "# num_residual_hiddens = 32\n",
        "# num_residual_layers = 2\n",
        "\n",
        "# This value is not that important, usually 64 works.\n",
        "# This will not change the capacity in the information-bottleneck.\n",
        "embedding_dim = 64\n",
        "\n",
        "# The higher this value, the higher the capacity in the information bottleneck.\n",
        "num_embeddings = 256\n",
        "\n",
        "# commitment_cost should be set appropriately. It's often useful to try a couple\n",
        "# of values. It mostly depends on the scale of the reconstruction cost\n",
        "# (log p(x|z)). So if the reconstruction cost is 100x higher, the\n",
        "# commitment_cost should also be multiplied with the same amount.\n",
        "commitment_cost = 0.25\n",
        "\n",
        "# Use EMA updates for the codebook (instead of the Adam optimizer).\n",
        "# This typically converges faster, and makes the model less dependent on choice\n",
        "# of the optimizer. In the VQ-VAE paper EMA updates were not used (but was\n",
        "# developed afterwards). See Appendix of the paper for more details.\n",
        "vq_use_ema = False\n",
        "\n",
        "# This is only used for EMA updates.\n",
        "decay = 0.99\n",
        "\n",
        "learning_rate = 3e-4\n",
        "\n",
        "# Data Loading.\n",
        "train_dataset_iterator = (\n",
        "    tf.data.Dataset.from_tensor_slices(train_dict)\n",
        "    .map(cast_and_normalise_images)\n",
        "    .shuffle(10000)\n",
        "    .repeat(-1)  # repeat indefinitely\n",
        "    .batch(batch_size)).make_one_shot_iterator()\n",
        "\n",
        "test_dataset_iterator = (\n",
        "    tf.data.Dataset.from_tensor_slices(test_dict)\n",
        "    .map(cast_and_normalise_images)\n",
        "    .repeat(1)  # 1 epoch\n",
        "    .batch(batch_size)).make_initializable_iterator()\n",
        "train_dataset_batch = train_dataset_iterator.get_next()\n",
        "test_dataset_batch = test_dataset_iterator.get_next()\n",
        "\n",
        "\n",
        "\n",
        "def get_images(sess, subset='train'):\n",
        "  if subset == 'train':\n",
        "    return sess.run(train_dataset_batch)\n",
        "  elif subset == 'test':\n",
        "    return sess.run(test_dataset_batch)\n",
        "  \n",
        "batch_size_classification=1\n",
        "train_dataset_iterator_classification = (\n",
        "    tf.data.Dataset.from_tensor_slices(train_dict)\n",
        "    .map(cast_and_normalise_images)\n",
        "    .repeat(1)\n",
        "    .batch(batch_size_classification)).make_one_shot_iterator()\n",
        "test_dataset_iterator_classification = (\n",
        "    tf.data.Dataset.from_tensor_slices(test_dict)\n",
        "    .map(cast_and_normalise_images)\n",
        "    .repeat(1)  \n",
        "    .batch(batch_size_classification)).make_one_shot_iterator()\n",
        "train_dataset_batch_classification = train_dataset_iterator_classification.get_next()\n",
        "test_dataset_batch_classification = test_dataset_iterator_classification.get_next()\n",
        "\n",
        "def get_images_classification(sess, subset='train'):\n",
        "  if subset == 'train':\n",
        "    return sess.run(train_dataset_batch_classification)\n",
        "  elif subset == 'test':\n",
        "    return sess.run(test_dataset_batch_classification)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4MeqjJ2vOsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2018 The Sonnet Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#    http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ============================================================================\n",
        "\"\"\"Sonnet implementation of VQ-VAE https://arxiv.org/abs/1711.00937.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from sonnet.python.modules import base\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.training import moving_averages\n",
        "\n",
        "\n",
        "class VectorQuantizer(base.AbstractModule):\n",
        "  \"\"\"Sonnet module representing the VQ-VAE layer.\n",
        "  Implements the algorithm presented in\n",
        "  'Neural Discrete Representation Learning' by van den Oord et al.\n",
        "  https://arxiv.org/abs/1711.00937\n",
        "  Input any tensor to be quantized. Last dimension will be used as space in\n",
        "  which to quantize. All other dimensions will be flattened and will be seen\n",
        "  as different examples to quantize.\n",
        "  The output tensor will have the same shape as the input.\n",
        "  For example a tensor with shape [16, 32, 32, 64] will be reshaped into\n",
        "  [16384, 64] and all 16384 vectors (each of 64 dimensions)  will be quantized\n",
        "  independently.\n",
        "  Args:\n",
        "    embedding_dim: integer representing the dimensionality of the tensors in the\n",
        "      quantized space. Inputs to the modules must be in this format as well.\n",
        "    num_embeddings: integer, the number of vectors in the quantized space.\n",
        "    commitment_cost: scalar which controls the weighting of the loss terms\n",
        "      (see equation 4 in the paper - this variable is Beta).\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, embedding_dim, num_embeddings, commitment_cost,\n",
        "               name='vq_layer'):\n",
        "    super(VectorQuantizer, self).__init__(name=name)\n",
        "    self._embedding_dim = embedding_dim\n",
        "    self._num_embeddings = num_embeddings\n",
        "    self._commitment_cost = commitment_cost\n",
        "\n",
        "    with self._enter_variable_scope():\n",
        "      initializer = tf.uniform_unit_scaling_initializer()\n",
        "      self._w = tf.get_variable('embedding', [embedding_dim, num_embeddings],\n",
        "                                initializer=initializer, trainable=True)\n",
        "\n",
        "  def _build(self, inputs, is_training):\n",
        "    \"\"\"Connects the module to some inputs.\n",
        "    Args:\n",
        "      inputs: Tensor, final dimension must be equal to embedding_dim. All other\n",
        "        leading dimensions will be flattened and treated as a large batch.\n",
        "      is_training: boolean, whether this connection is to training data.\n",
        "    Returns:\n",
        "      dict containing the following keys and values:\n",
        "        quantize: Tensor containing the quantized version of the input.\n",
        "        loss: Tensor containing the loss to optimize.\n",
        "        perplexity: Tensor containing the perplexity of the encodings.\n",
        "        encodings: Tensor containing the discrete encodings, ie which element\n",
        "          of the quantized space each input element was mapped to.\n",
        "        encoding_indices: Tensor containing the discrete encoding indices, ie\n",
        "          which element of the quantized space each input element was mapped to.\n",
        "    \"\"\"\n",
        "    # Assert last dimension is same as self._embedding_dim\n",
        "    input_shape = tf.shape(inputs)\n",
        "    with tf.control_dependencies([\n",
        "        tf.Assert(tf.equal(input_shape[-1], self._embedding_dim),\n",
        "                  [input_shape])]):\n",
        "      flat_inputs = tf.reshape(inputs, [-1, self._embedding_dim])\n",
        "\n",
        "    distances = (tf.reduce_sum(flat_inputs**2, 1, keepdims=True)\n",
        "                 - 2 * tf.matmul(flat_inputs, self._w)\n",
        "                 + tf.reduce_sum(self._w ** 2, 0, keepdims=True))\n",
        "\n",
        "    encoding_indices_old = tf.argmax(- distances, 1)\n",
        "    encodings = tf.one_hot(encoding_indices_old, self._num_embeddings)\n",
        "    encoding_indices = tf.reshape(encoding_indices_old, tf.shape(inputs)[:-1])\n",
        "    quantized = self.quantize(encoding_indices)\n",
        "\n",
        "    lamda = 1\n",
        "    e_latent_loss = tf.reduce_mean((tf.stop_gradient(quantized) - inputs) ** 2)\n",
        "    q_latent_loss = tf.reduce_mean((quantized - tf.stop_gradient(inputs)) ** 2)\n",
        "    loss = lamda * q_latent_loss + self._commitment_cost * e_latent_loss\n",
        "\n",
        "    quantized = inputs + tf.stop_gradient(quantized - inputs)\n",
        "    avg_probs = tf.reduce_mean(encodings, 0)\n",
        "    perplexity = tf.exp(- tf.reduce_sum(avg_probs * tf.log(avg_probs + 1e-10)))\n",
        "\n",
        "    return {'quantize': quantized,\n",
        "            'loss': loss,\n",
        "            'perplexity': perplexity,\n",
        "            'encodings': encodings,\n",
        "            'encoding_indices': encoding_indices,'encoding_indices_old': encoding_indices_old,}\n",
        "\n",
        "  @property\n",
        "  def embeddings(self):\n",
        "    return self._w\n",
        "\n",
        "  def quantize(self, encoding_indices):\n",
        "    with tf.control_dependencies([encoding_indices]):\n",
        "      w = tf.transpose(self.embeddings.read_value(), [1, 0])\n",
        "    return tf.nn.embedding_lookup(w, encoding_indices, validate_indices=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoFD04lTz0q9",
        "colab_type": "code",
        "outputId": "b201babc-ee12-4a23-d98c-892645213d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 27339
        }
      },
      "source": [
        "\n",
        "# Build modules.\n",
        "encoder = Encoder(num_hiddens, num_residual_layers, num_residual_hiddens)\n",
        "decoder = Decoder(num_hiddens, num_residual_layers, num_residual_hiddens)\n",
        "pre_vq_conv1 = snt.Conv2D(output_channels=embedding_dim,\n",
        "    kernel_shape=(1, 1),\n",
        "    stride=(1, 1),\n",
        "    name=\"to_vq\") # (?, 8, 8, 64)\n",
        "\n",
        "if vq_use_ema:\n",
        "  vq_vae =VectorQuantizerEMA(\n",
        "      embedding_dim=embedding_dim,\n",
        "      num_embeddings=num_embeddings,\n",
        "      commitment_cost=commitment_cost,\n",
        "      decay=decay)\n",
        "else:\n",
        "  vq_vae =VectorQuantizer(\n",
        "      embedding_dim=embedding_dim,\n",
        "      num_embeddings=num_embeddings,\n",
        "      commitment_cost=commitment_cost)\n",
        "\n",
        "# Process inputs with conv stack, finishing with 1x1 to get to correct size.\n",
        "x = tf.placeholder(tf.float32, shape=(None, image_size, image_size, 1))\n",
        "z = pre_vq_conv1(encoder(x))\n",
        "\n",
        "# vq_output_train[\"quantize\"] are the quantized outputs of the encoder.\n",
        "# That is also what is used during training with the straight-through estimator. \n",
        "# To get the one-hot coded assignments use vq_output_train[\"encodings\"] instead.\n",
        "# These encodings will not pass gradients into to encoder, \n",
        "# but can be used to train a PixelCNN on top afterwards.\n",
        "\n",
        "# For training\n",
        "vq_output_train = vq_vae(z, is_training=True)\n",
        "x_recon = decoder(vq_output_train[\"quantize\"])\n",
        "recon_error = tf.reduce_mean((x_recon - x)**2) / data_variance  # Normalized MSE\n",
        "loss = recon_error + vq_output_train[\"loss\"]\n",
        "\n",
        "# For evaluation, make sure is_training=False!\n",
        "vq_output_eval = vq_vae(z, is_training=False)\n",
        "x_recon_eval = decoder(vq_output_eval[\"quantize\"])\n",
        "codebook=vq_vae.embeddings\n",
        "indices= vq_output_train[\"encoding_indices\"]\n",
        "indices_old = vq_output_train[\"encoding_indices_old\"]\n",
        "\n",
        "# The following is a useful value to track during training.\n",
        "# It indicates how many codes are 'active' on average.\n",
        "perplexity = vq_output_train[\"perplexity\"] \n",
        "\n",
        "# Create optimizer and TF session.\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss)\n",
        "sess = tf.train.SingularMonitoredSession()\n",
        "# Train.\n",
        "train_res_recon_error = []\n",
        "train_res_perplexity = []\n",
        "for i in xrange(num_training_updates):\n",
        "  feed_dict = {x: get_images(sess)['images']}\n",
        "  if i!=num_training_updates:\n",
        "    results = sess.run([train_op, recon_error, perplexity,codebook],\n",
        "                       feed_dict=feed_dict)\n",
        "    train_res_recon_error.append(results[1])\n",
        "    train_res_perplexity.append(results[2])\n",
        "  else:\n",
        "    results = sess.run([train_op, recon_error, perplexity,codebook],\n",
        "                       feed_dict=feed_dict)\n",
        "    train_res_recon_error.append(results[1])\n",
        "    train_res_perplexity.append(results[2])\n",
        "  if (i+1) % 100 == 0:\n",
        "    print('%d iterations' % (i+1))\n",
        "    print('recon_error: %.3f' % np.mean(train_res_recon_error[-100:]))\n",
        "    print('perplexity: %.3f' % np.mean(train_res_perplexity[-100:]))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-19189e3cf4f3>:43: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "100 iterations\n",
            "recon_error: 1.111\n",
            "perplexity: 2.548\n",
            "\n",
            "200 iterations\n",
            "recon_error: 0.419\n",
            "perplexity: 3.514\n",
            "\n",
            "300 iterations\n",
            "recon_error: 0.271\n",
            "perplexity: 7.099\n",
            "\n",
            "400 iterations\n",
            "recon_error: 0.207\n",
            "perplexity: 10.336\n",
            "\n",
            "500 iterations\n",
            "recon_error: 0.178\n",
            "perplexity: 13.370\n",
            "\n",
            "600 iterations\n",
            "recon_error: 0.165\n",
            "perplexity: 15.403\n",
            "\n",
            "700 iterations\n",
            "recon_error: 0.153\n",
            "perplexity: 16.152\n",
            "\n",
            "800 iterations\n",
            "recon_error: 0.145\n",
            "perplexity: 17.017\n",
            "\n",
            "900 iterations\n",
            "recon_error: 0.140\n",
            "perplexity: 18.477\n",
            "\n",
            "1000 iterations\n",
            "recon_error: 0.138\n",
            "perplexity: 20.329\n",
            "\n",
            "1100 iterations\n",
            "recon_error: 0.131\n",
            "perplexity: 20.882\n",
            "\n",
            "1200 iterations\n",
            "recon_error: 0.130\n",
            "perplexity: 21.683\n",
            "\n",
            "1300 iterations\n",
            "recon_error: 0.126\n",
            "perplexity: 22.090\n",
            "\n",
            "1400 iterations\n",
            "recon_error: 0.122\n",
            "perplexity: 22.647\n",
            "\n",
            "1500 iterations\n",
            "recon_error: 0.119\n",
            "perplexity: 23.594\n",
            "\n",
            "1600 iterations\n",
            "recon_error: 0.116\n",
            "perplexity: 24.671\n",
            "\n",
            "1700 iterations\n",
            "recon_error: 0.113\n",
            "perplexity: 25.966\n",
            "\n",
            "1800 iterations\n",
            "recon_error: 0.111\n",
            "perplexity: 27.088\n",
            "\n",
            "1900 iterations\n",
            "recon_error: 0.109\n",
            "perplexity: 27.873\n",
            "\n",
            "2000 iterations\n",
            "recon_error: 0.105\n",
            "perplexity: 28.630\n",
            "\n",
            "2100 iterations\n",
            "recon_error: 0.105\n",
            "perplexity: 29.351\n",
            "\n",
            "2200 iterations\n",
            "recon_error: 0.102\n",
            "perplexity: 30.282\n",
            "\n",
            "2300 iterations\n",
            "recon_error: 0.100\n",
            "perplexity: 30.933\n",
            "\n",
            "2400 iterations\n",
            "recon_error: 0.097\n",
            "perplexity: 31.703\n",
            "\n",
            "2500 iterations\n",
            "recon_error: 0.098\n",
            "perplexity: 32.623\n",
            "\n",
            "2600 iterations\n",
            "recon_error: 0.096\n",
            "perplexity: 33.567\n",
            "\n",
            "2700 iterations\n",
            "recon_error: 0.092\n",
            "perplexity: 34.505\n",
            "\n",
            "2800 iterations\n",
            "recon_error: 0.093\n",
            "perplexity: 35.369\n",
            "\n",
            "2900 iterations\n",
            "recon_error: 0.091\n",
            "perplexity: 36.078\n",
            "\n",
            "3000 iterations\n",
            "recon_error: 0.091\n",
            "perplexity: 36.946\n",
            "\n",
            "3100 iterations\n",
            "recon_error: 0.089\n",
            "perplexity: 38.240\n",
            "\n",
            "3200 iterations\n",
            "recon_error: 0.088\n",
            "perplexity: 39.053\n",
            "\n",
            "3300 iterations\n",
            "recon_error: 0.085\n",
            "perplexity: 39.949\n",
            "\n",
            "3400 iterations\n",
            "recon_error: 0.085\n",
            "perplexity: 40.871\n",
            "\n",
            "3500 iterations\n",
            "recon_error: 0.083\n",
            "perplexity: 41.714\n",
            "\n",
            "3600 iterations\n",
            "recon_error: 0.084\n",
            "perplexity: 43.020\n",
            "\n",
            "3700 iterations\n",
            "recon_error: 0.082\n",
            "perplexity: 43.835\n",
            "\n",
            "3800 iterations\n",
            "recon_error: 0.080\n",
            "perplexity: 44.887\n",
            "\n",
            "3900 iterations\n",
            "recon_error: 0.078\n",
            "perplexity: 45.382\n",
            "\n",
            "4000 iterations\n",
            "recon_error: 0.078\n",
            "perplexity: 45.988\n",
            "\n",
            "4100 iterations\n",
            "recon_error: 0.077\n",
            "perplexity: 46.484\n",
            "\n",
            "4200 iterations\n",
            "recon_error: 0.077\n",
            "perplexity: 47.284\n",
            "\n",
            "4300 iterations\n",
            "recon_error: 0.074\n",
            "perplexity: 47.665\n",
            "\n",
            "4400 iterations\n",
            "recon_error: 0.074\n",
            "perplexity: 48.076\n",
            "\n",
            "4500 iterations\n",
            "recon_error: 0.074\n",
            "perplexity: 48.380\n",
            "\n",
            "4600 iterations\n",
            "recon_error: 0.072\n",
            "perplexity: 48.892\n",
            "\n",
            "4700 iterations\n",
            "recon_error: 0.071\n",
            "perplexity: 49.245\n",
            "\n",
            "4800 iterations\n",
            "recon_error: 0.071\n",
            "perplexity: 49.663\n",
            "\n",
            "4900 iterations\n",
            "recon_error: 0.070\n",
            "perplexity: 50.114\n",
            "\n",
            "5000 iterations\n",
            "recon_error: 0.070\n",
            "perplexity: 50.553\n",
            "\n",
            "5100 iterations\n",
            "recon_error: 0.069\n",
            "perplexity: 50.793\n",
            "\n",
            "5200 iterations\n",
            "recon_error: 0.068\n",
            "perplexity: 50.914\n",
            "\n",
            "5300 iterations\n",
            "recon_error: 0.066\n",
            "perplexity: 51.256\n",
            "\n",
            "5400 iterations\n",
            "recon_error: 0.066\n",
            "perplexity: 51.587\n",
            "\n",
            "5500 iterations\n",
            "recon_error: 0.065\n",
            "perplexity: 51.966\n",
            "\n",
            "5600 iterations\n",
            "recon_error: 0.064\n",
            "perplexity: 52.560\n",
            "\n",
            "5700 iterations\n",
            "recon_error: 0.064\n",
            "perplexity: 52.740\n",
            "\n",
            "5800 iterations\n",
            "recon_error: 0.063\n",
            "perplexity: 53.092\n",
            "\n",
            "5900 iterations\n",
            "recon_error: 0.062\n",
            "perplexity: 53.252\n",
            "\n",
            "6000 iterations\n",
            "recon_error: 0.062\n",
            "perplexity: 53.716\n",
            "\n",
            "6100 iterations\n",
            "recon_error: 0.061\n",
            "perplexity: 53.648\n",
            "\n",
            "6200 iterations\n",
            "recon_error: 0.060\n",
            "perplexity: 54.001\n",
            "\n",
            "6300 iterations\n",
            "recon_error: 0.060\n",
            "perplexity: 54.396\n",
            "\n",
            "6400 iterations\n",
            "recon_error: 0.059\n",
            "perplexity: 55.043\n",
            "\n",
            "6500 iterations\n",
            "recon_error: 0.058\n",
            "perplexity: 54.809\n",
            "\n",
            "6600 iterations\n",
            "recon_error: 0.058\n",
            "perplexity: 55.480\n",
            "\n",
            "6700 iterations\n",
            "recon_error: 0.057\n",
            "perplexity: 55.424\n",
            "\n",
            "6800 iterations\n",
            "recon_error: 0.057\n",
            "perplexity: 55.912\n",
            "\n",
            "6900 iterations\n",
            "recon_error: 0.058\n",
            "perplexity: 56.243\n",
            "\n",
            "7000 iterations\n",
            "recon_error: 0.057\n",
            "perplexity: 56.503\n",
            "\n",
            "7100 iterations\n",
            "recon_error: 0.056\n",
            "perplexity: 56.989\n",
            "\n",
            "7200 iterations\n",
            "recon_error: 0.055\n",
            "perplexity: 57.358\n",
            "\n",
            "7300 iterations\n",
            "recon_error: 0.055\n",
            "perplexity: 57.749\n",
            "\n",
            "7400 iterations\n",
            "recon_error: 0.056\n",
            "perplexity: 58.448\n",
            "\n",
            "7500 iterations\n",
            "recon_error: 0.054\n",
            "perplexity: 58.318\n",
            "\n",
            "7600 iterations\n",
            "recon_error: 0.053\n",
            "perplexity: 58.158\n",
            "\n",
            "7700 iterations\n",
            "recon_error: 0.052\n",
            "perplexity: 58.250\n",
            "\n",
            "7800 iterations\n",
            "recon_error: 0.053\n",
            "perplexity: 58.538\n",
            "\n",
            "7900 iterations\n",
            "recon_error: 0.051\n",
            "perplexity: 58.681\n",
            "\n",
            "8000 iterations\n",
            "recon_error: 0.052\n",
            "perplexity: 58.583\n",
            "\n",
            "8100 iterations\n",
            "recon_error: 0.052\n",
            "perplexity: 58.987\n",
            "\n",
            "8200 iterations\n",
            "recon_error: 0.051\n",
            "perplexity: 59.417\n",
            "\n",
            "8300 iterations\n",
            "recon_error: 0.051\n",
            "perplexity: 59.300\n",
            "\n",
            "8400 iterations\n",
            "recon_error: 0.050\n",
            "perplexity: 59.158\n",
            "\n",
            "8500 iterations\n",
            "recon_error: 0.050\n",
            "perplexity: 59.690\n",
            "\n",
            "8600 iterations\n",
            "recon_error: 0.050\n",
            "perplexity: 59.617\n",
            "\n",
            "8700 iterations\n",
            "recon_error: 0.050\n",
            "perplexity: 60.220\n",
            "\n",
            "8800 iterations\n",
            "recon_error: 0.049\n",
            "perplexity: 60.518\n",
            "\n",
            "8900 iterations\n",
            "recon_error: 0.048\n",
            "perplexity: 60.448\n",
            "\n",
            "9000 iterations\n",
            "recon_error: 0.048\n",
            "perplexity: 60.734\n",
            "\n",
            "9100 iterations\n",
            "recon_error: 0.049\n",
            "perplexity: 61.368\n",
            "\n",
            "9200 iterations\n",
            "recon_error: 0.048\n",
            "perplexity: 61.657\n",
            "\n",
            "9300 iterations\n",
            "recon_error: 0.047\n",
            "perplexity: 62.091\n",
            "\n",
            "9400 iterations\n",
            "recon_error: 0.047\n",
            "perplexity: 62.444\n",
            "\n",
            "9500 iterations\n",
            "recon_error: 0.047\n",
            "perplexity: 62.566\n",
            "\n",
            "9600 iterations\n",
            "recon_error: 0.047\n",
            "perplexity: 63.241\n",
            "\n",
            "9700 iterations\n",
            "recon_error: 0.046\n",
            "perplexity: 63.436\n",
            "\n",
            "9800 iterations\n",
            "recon_error: 0.045\n",
            "perplexity: 63.922\n",
            "\n",
            "9900 iterations\n",
            "recon_error: 0.045\n",
            "perplexity: 63.856\n",
            "\n",
            "10000 iterations\n",
            "recon_error: 0.045\n",
            "perplexity: 63.851\n",
            "\n",
            "10100 iterations\n",
            "recon_error: 0.045\n",
            "perplexity: 63.969\n",
            "\n",
            "10200 iterations\n",
            "recon_error: 0.045\n",
            "perplexity: 64.365\n",
            "\n",
            "10300 iterations\n",
            "recon_error: 0.044\n",
            "perplexity: 64.279\n",
            "\n",
            "10400 iterations\n",
            "recon_error: 0.044\n",
            "perplexity: 64.398\n",
            "\n",
            "10500 iterations\n",
            "recon_error: 0.045\n",
            "perplexity: 65.102\n",
            "\n",
            "10600 iterations\n",
            "recon_error: 0.044\n",
            "perplexity: 65.044\n",
            "\n",
            "10700 iterations\n",
            "recon_error: 0.044\n",
            "perplexity: 64.447\n",
            "\n",
            "10800 iterations\n",
            "recon_error: 0.044\n",
            "perplexity: 64.887\n",
            "\n",
            "10900 iterations\n",
            "recon_error: 0.043\n",
            "perplexity: 64.828\n",
            "\n",
            "11000 iterations\n",
            "recon_error: 0.044\n",
            "perplexity: 65.376\n",
            "\n",
            "11100 iterations\n",
            "recon_error: 0.043\n",
            "perplexity: 65.498\n",
            "\n",
            "11200 iterations\n",
            "recon_error: 0.043\n",
            "perplexity: 65.462\n",
            "\n",
            "11300 iterations\n",
            "recon_error: 0.042\n",
            "perplexity: 65.229\n",
            "\n",
            "11400 iterations\n",
            "recon_error: 0.042\n",
            "perplexity: 64.844\n",
            "\n",
            "11500 iterations\n",
            "recon_error: 0.042\n",
            "perplexity: 65.024\n",
            "\n",
            "11600 iterations\n",
            "recon_error: 0.042\n",
            "perplexity: 65.024\n",
            "\n",
            "11700 iterations\n",
            "recon_error: 0.042\n",
            "perplexity: 65.350\n",
            "\n",
            "11800 iterations\n",
            "recon_error: 0.041\n",
            "perplexity: 64.972\n",
            "\n",
            "11900 iterations\n",
            "recon_error: 0.042\n",
            "perplexity: 65.728\n",
            "\n",
            "12000 iterations\n",
            "recon_error: 0.041\n",
            "perplexity: 65.149\n",
            "\n",
            "12100 iterations\n",
            "recon_error: 0.041\n",
            "perplexity: 65.360\n",
            "\n",
            "12200 iterations\n",
            "recon_error: 0.041\n",
            "perplexity: 65.543\n",
            "\n",
            "12300 iterations\n",
            "recon_error: 0.041\n",
            "perplexity: 65.761\n",
            "\n",
            "12400 iterations\n",
            "recon_error: 0.041\n",
            "perplexity: 65.822\n",
            "\n",
            "12500 iterations\n",
            "recon_error: 0.040\n",
            "perplexity: 65.766\n",
            "\n",
            "12600 iterations\n",
            "recon_error: 0.041\n",
            "perplexity: 66.155\n",
            "\n",
            "12700 iterations\n",
            "recon_error: 0.040\n",
            "perplexity: 65.425\n",
            "\n",
            "12800 iterations\n",
            "recon_error: 0.040\n",
            "perplexity: 66.026\n",
            "\n",
            "12900 iterations\n",
            "recon_error: 0.040\n",
            "perplexity: 66.263\n",
            "\n",
            "13000 iterations\n",
            "recon_error: 0.040\n",
            "perplexity: 65.727\n",
            "\n",
            "13100 iterations\n",
            "recon_error: 0.040\n",
            "perplexity: 66.428\n",
            "\n",
            "13200 iterations\n",
            "recon_error: 0.039\n",
            "perplexity: 65.643\n",
            "\n",
            "13300 iterations\n",
            "recon_error: 0.040\n",
            "perplexity: 65.817\n",
            "\n",
            "13400 iterations\n",
            "recon_error: 0.039\n",
            "perplexity: 65.923\n",
            "\n",
            "13500 iterations\n",
            "recon_error: 0.038\n",
            "perplexity: 65.279\n",
            "\n",
            "13600 iterations\n",
            "recon_error: 0.039\n",
            "perplexity: 65.977\n",
            "\n",
            "13700 iterations\n",
            "recon_error: 0.038\n",
            "perplexity: 66.103\n",
            "\n",
            "13800 iterations\n",
            "recon_error: 0.038\n",
            "perplexity: 65.855\n",
            "\n",
            "13900 iterations\n",
            "recon_error: 0.039\n",
            "perplexity: 66.441\n",
            "\n",
            "14000 iterations\n",
            "recon_error: 0.039\n",
            "perplexity: 66.368\n",
            "\n",
            "14100 iterations\n",
            "recon_error: 0.038\n",
            "perplexity: 66.020\n",
            "\n",
            "14200 iterations\n",
            "recon_error: 0.038\n",
            "perplexity: 65.927\n",
            "\n",
            "14300 iterations\n",
            "recon_error: 0.038\n",
            "perplexity: 66.397\n",
            "\n",
            "14400 iterations\n",
            "recon_error: 0.038\n",
            "perplexity: 66.781\n",
            "\n",
            "14500 iterations\n",
            "recon_error: 0.038\n",
            "perplexity: 66.415\n",
            "\n",
            "14600 iterations\n",
            "recon_error: 0.038\n",
            "perplexity: 66.618\n",
            "\n",
            "14700 iterations\n",
            "recon_error: 0.037\n",
            "perplexity: 66.539\n",
            "\n",
            "14800 iterations\n",
            "recon_error: 0.038\n",
            "perplexity: 66.838\n",
            "\n",
            "14900 iterations\n",
            "recon_error: 0.038\n",
            "perplexity: 67.144\n",
            "\n",
            "15000 iterations\n",
            "recon_error: 0.037\n",
            "perplexity: 67.139\n",
            "\n",
            "15100 iterations\n",
            "recon_error: 0.037\n",
            "perplexity: 66.635\n",
            "\n",
            "15200 iterations\n",
            "recon_error: 0.037\n",
            "perplexity: 66.496\n",
            "\n",
            "15300 iterations\n",
            "recon_error: 0.036\n",
            "perplexity: 66.607\n",
            "\n",
            "15400 iterations\n",
            "recon_error: 0.037\n",
            "perplexity: 67.057\n",
            "\n",
            "15500 iterations\n",
            "recon_error: 0.036\n",
            "perplexity: 67.045\n",
            "\n",
            "15600 iterations\n",
            "recon_error: 0.036\n",
            "perplexity: 67.117\n",
            "\n",
            "15700 iterations\n",
            "recon_error: 0.036\n",
            "perplexity: 67.094\n",
            "\n",
            "15800 iterations\n",
            "recon_error: 0.036\n",
            "perplexity: 66.736\n",
            "\n",
            "15900 iterations\n",
            "recon_error: 0.036\n",
            "perplexity: 67.111\n",
            "\n",
            "16000 iterations\n",
            "recon_error: 0.036\n",
            "perplexity: 67.147\n",
            "\n",
            "16100 iterations\n",
            "recon_error: 0.036\n",
            "perplexity: 66.863\n",
            "\n",
            "16200 iterations\n",
            "recon_error: 0.036\n",
            "perplexity: 67.734\n",
            "\n",
            "16300 iterations\n",
            "recon_error: 0.036\n",
            "perplexity: 67.514\n",
            "\n",
            "16400 iterations\n",
            "recon_error: 0.036\n",
            "perplexity: 68.025\n",
            "\n",
            "16500 iterations\n",
            "recon_error: 0.035\n",
            "perplexity: 67.456\n",
            "\n",
            "16600 iterations\n",
            "recon_error: 0.036\n",
            "perplexity: 67.655\n",
            "\n",
            "16700 iterations\n",
            "recon_error: 0.036\n",
            "perplexity: 68.340\n",
            "\n",
            "16800 iterations\n",
            "recon_error: 0.035\n",
            "perplexity: 67.137\n",
            "\n",
            "16900 iterations\n",
            "recon_error: 0.035\n",
            "perplexity: 68.010\n",
            "\n",
            "17000 iterations\n",
            "recon_error: 0.034\n",
            "perplexity: 67.523\n",
            "\n",
            "17100 iterations\n",
            "recon_error: 0.034\n",
            "perplexity: 67.343\n",
            "\n",
            "17200 iterations\n",
            "recon_error: 0.035\n",
            "perplexity: 67.617\n",
            "\n",
            "17300 iterations\n",
            "recon_error: 0.034\n",
            "perplexity: 67.281\n",
            "\n",
            "17400 iterations\n",
            "recon_error: 0.034\n",
            "perplexity: 67.309\n",
            "\n",
            "17500 iterations\n",
            "recon_error: 0.034\n",
            "perplexity: 67.482\n",
            "\n",
            "17600 iterations\n",
            "recon_error: 0.034\n",
            "perplexity: 67.876\n",
            "\n",
            "17700 iterations\n",
            "recon_error: 0.034\n",
            "perplexity: 67.906\n",
            "\n",
            "17800 iterations\n",
            "recon_error: 0.034\n",
            "perplexity: 68.126\n",
            "\n",
            "17900 iterations\n",
            "recon_error: 0.035\n",
            "perplexity: 68.579\n",
            "\n",
            "18000 iterations\n",
            "recon_error: 0.034\n",
            "perplexity: 67.950\n",
            "\n",
            "18100 iterations\n",
            "recon_error: 0.033\n",
            "perplexity: 68.239\n",
            "\n",
            "18200 iterations\n",
            "recon_error: 0.034\n",
            "perplexity: 68.161\n",
            "\n",
            "18300 iterations\n",
            "recon_error: 0.034\n",
            "perplexity: 68.701\n",
            "\n",
            "18400 iterations\n",
            "recon_error: 0.034\n",
            "perplexity: 68.645\n",
            "\n",
            "18500 iterations\n",
            "recon_error: 0.034\n",
            "perplexity: 68.749\n",
            "\n",
            "18600 iterations\n",
            "recon_error: 0.034\n",
            "perplexity: 68.644\n",
            "\n",
            "18700 iterations\n",
            "recon_error: 0.034\n",
            "perplexity: 68.456\n",
            "\n",
            "18800 iterations\n",
            "recon_error: 0.033\n",
            "perplexity: 68.201\n",
            "\n",
            "18900 iterations\n",
            "recon_error: 0.033\n",
            "perplexity: 68.201\n",
            "\n",
            "19000 iterations\n",
            "recon_error: 0.033\n",
            "perplexity: 68.653\n",
            "\n",
            "19100 iterations\n",
            "recon_error: 0.033\n",
            "perplexity: 68.503\n",
            "\n",
            "19200 iterations\n",
            "recon_error: 0.033\n",
            "perplexity: 68.397\n",
            "\n",
            "19300 iterations\n",
            "recon_error: 0.032\n",
            "perplexity: 68.265\n",
            "\n",
            "19400 iterations\n",
            "recon_error: 0.033\n",
            "perplexity: 68.647\n",
            "\n",
            "19500 iterations\n",
            "recon_error: 0.033\n",
            "perplexity: 68.398\n",
            "\n",
            "19600 iterations\n",
            "recon_error: 0.033\n",
            "perplexity: 68.705\n",
            "\n",
            "19700 iterations\n",
            "recon_error: 0.032\n",
            "perplexity: 68.514\n",
            "\n",
            "19800 iterations\n",
            "recon_error: 0.032\n",
            "perplexity: 68.702\n",
            "\n",
            "19900 iterations\n",
            "recon_error: 0.032\n",
            "perplexity: 68.841\n",
            "\n",
            "20000 iterations\n",
            "recon_error: 0.033\n",
            "perplexity: 68.918\n",
            "\n",
            "20100 iterations\n",
            "recon_error: 0.033\n",
            "perplexity: 69.350\n",
            "\n",
            "20200 iterations\n",
            "recon_error: 0.033\n",
            "perplexity: 69.023\n",
            "\n",
            "20300 iterations\n",
            "recon_error: 0.032\n",
            "perplexity: 69.046\n",
            "\n",
            "20400 iterations\n",
            "recon_error: 0.032\n",
            "perplexity: 69.267\n",
            "\n",
            "20500 iterations\n",
            "recon_error: 0.032\n",
            "perplexity: 69.113\n",
            "\n",
            "20600 iterations\n",
            "recon_error: 0.033\n",
            "perplexity: 69.864\n",
            "\n",
            "20700 iterations\n",
            "recon_error: 0.032\n",
            "perplexity: 68.821\n",
            "\n",
            "20800 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 68.690\n",
            "\n",
            "20900 iterations\n",
            "recon_error: 0.032\n",
            "perplexity: 69.138\n",
            "\n",
            "21000 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.514\n",
            "\n",
            "21100 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 68.588\n",
            "\n",
            "21200 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 68.530\n",
            "\n",
            "21300 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.215\n",
            "\n",
            "21400 iterations\n",
            "recon_error: 0.032\n",
            "perplexity: 69.270\n",
            "\n",
            "21500 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.368\n",
            "\n",
            "21600 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.072\n",
            "\n",
            "21700 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.067\n",
            "\n",
            "21800 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.659\n",
            "\n",
            "21900 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.271\n",
            "\n",
            "22000 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.319\n",
            "\n",
            "22100 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.432\n",
            "\n",
            "22200 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.066\n",
            "\n",
            "22300 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.674\n",
            "\n",
            "22400 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.988\n",
            "\n",
            "22500 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.709\n",
            "\n",
            "22600 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.199\n",
            "\n",
            "22700 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.575\n",
            "\n",
            "22800 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 68.781\n",
            "\n",
            "22900 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.248\n",
            "\n",
            "23000 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.381\n",
            "\n",
            "23100 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.515\n",
            "\n",
            "23200 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.034\n",
            "\n",
            "23300 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.902\n",
            "\n",
            "23400 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 68.941\n",
            "\n",
            "23500 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.177\n",
            "\n",
            "23600 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.566\n",
            "\n",
            "23700 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.603\n",
            "\n",
            "23800 iterations\n",
            "recon_error: 0.031\n",
            "perplexity: 69.639\n",
            "\n",
            "23900 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.778\n",
            "\n",
            "24000 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 68.888\n",
            "\n",
            "24100 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.359\n",
            "\n",
            "24200 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.510\n",
            "\n",
            "24300 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.966\n",
            "\n",
            "24400 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.600\n",
            "\n",
            "24500 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.306\n",
            "\n",
            "24600 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 68.995\n",
            "\n",
            "24700 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.684\n",
            "\n",
            "24800 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.997\n",
            "\n",
            "24900 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.373\n",
            "\n",
            "25000 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.240\n",
            "\n",
            "25100 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.227\n",
            "\n",
            "25200 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.454\n",
            "\n",
            "25300 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 69.617\n",
            "\n",
            "25400 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.489\n",
            "\n",
            "25500 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.130\n",
            "\n",
            "25600 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 70.170\n",
            "\n",
            "25700 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 70.032\n",
            "\n",
            "25800 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.387\n",
            "\n",
            "25900 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.599\n",
            "\n",
            "26000 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.872\n",
            "\n",
            "26100 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.949\n",
            "\n",
            "26200 iterations\n",
            "recon_error: 0.030\n",
            "perplexity: 70.399\n",
            "\n",
            "26300 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.572\n",
            "\n",
            "26400 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.576\n",
            "\n",
            "26500 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.451\n",
            "\n",
            "26600 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 68.844\n",
            "\n",
            "26700 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.818\n",
            "\n",
            "26800 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.255\n",
            "\n",
            "26900 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.836\n",
            "\n",
            "27000 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.031\n",
            "\n",
            "27100 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.494\n",
            "\n",
            "27200 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 70.294\n",
            "\n",
            "27300 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.319\n",
            "\n",
            "27400 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.160\n",
            "\n",
            "27500 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 70.191\n",
            "\n",
            "27600 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.501\n",
            "\n",
            "27700 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.828\n",
            "\n",
            "27800 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.637\n",
            "\n",
            "27900 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.997\n",
            "\n",
            "28000 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 70.285\n",
            "\n",
            "28100 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.975\n",
            "\n",
            "28200 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.682\n",
            "\n",
            "28300 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.492\n",
            "\n",
            "28400 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 68.958\n",
            "\n",
            "28500 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 70.176\n",
            "\n",
            "28600 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.491\n",
            "\n",
            "28700 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.311\n",
            "\n",
            "28800 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 70.033\n",
            "\n",
            "28900 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.859\n",
            "\n",
            "29000 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.763\n",
            "\n",
            "29100 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.478\n",
            "\n",
            "29200 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.538\n",
            "\n",
            "29300 iterations\n",
            "recon_error: 0.029\n",
            "perplexity: 69.842\n",
            "\n",
            "29400 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.774\n",
            "\n",
            "29500 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.712\n",
            "\n",
            "29600 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 70.069\n",
            "\n",
            "29700 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 70.259\n",
            "\n",
            "29800 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.880\n",
            "\n",
            "29900 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.964\n",
            "\n",
            "30000 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 70.228\n",
            "\n",
            "30100 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.682\n",
            "\n",
            "30200 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.276\n",
            "\n",
            "30300 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.834\n",
            "\n",
            "30400 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 69.352\n",
            "\n",
            "30500 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 69.714\n",
            "\n",
            "30600 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 69.467\n",
            "\n",
            "30700 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 70.130\n",
            "\n",
            "30800 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.582\n",
            "\n",
            "30900 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 70.136\n",
            "\n",
            "31000 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 69.869\n",
            "\n",
            "31100 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.797\n",
            "\n",
            "31200 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 69.860\n",
            "\n",
            "31300 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 70.741\n",
            "\n",
            "31400 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 70.200\n",
            "\n",
            "31500 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 69.918\n",
            "\n",
            "31600 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 70.273\n",
            "\n",
            "31700 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 70.433\n",
            "\n",
            "31800 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 69.979\n",
            "\n",
            "31900 iterations\n",
            "recon_error: 0.028\n",
            "perplexity: 70.672\n",
            "\n",
            "32000 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.202\n",
            "\n",
            "32100 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 69.994\n",
            "\n",
            "32200 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 69.713\n",
            "\n",
            "32300 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 69.988\n",
            "\n",
            "32400 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.009\n",
            "\n",
            "32500 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.217\n",
            "\n",
            "32600 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.028\n",
            "\n",
            "32700 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 69.275\n",
            "\n",
            "32800 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.825\n",
            "\n",
            "32900 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.534\n",
            "\n",
            "33000 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.712\n",
            "\n",
            "33100 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.687\n",
            "\n",
            "33200 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.468\n",
            "\n",
            "33300 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.963\n",
            "\n",
            "33400 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.710\n",
            "\n",
            "33500 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.520\n",
            "\n",
            "33600 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.500\n",
            "\n",
            "33700 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.401\n",
            "\n",
            "33800 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.768\n",
            "\n",
            "33900 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.269\n",
            "\n",
            "34000 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.061\n",
            "\n",
            "34100 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.206\n",
            "\n",
            "34200 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.218\n",
            "\n",
            "34300 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.347\n",
            "\n",
            "34400 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.923\n",
            "\n",
            "34500 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 71.002\n",
            "\n",
            "34600 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.704\n",
            "\n",
            "34700 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.674\n",
            "\n",
            "34800 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.597\n",
            "\n",
            "34900 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.528\n",
            "\n",
            "35000 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.156\n",
            "\n",
            "35100 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 71.112\n",
            "\n",
            "35200 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.802\n",
            "\n",
            "35300 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.528\n",
            "\n",
            "35400 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 71.069\n",
            "\n",
            "35500 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 70.894\n",
            "\n",
            "35600 iterations\n",
            "recon_error: 0.027\n",
            "perplexity: 71.021\n",
            "\n",
            "35700 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.124\n",
            "\n",
            "35800 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 69.973\n",
            "\n",
            "35900 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.051\n",
            "\n",
            "36000 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.648\n",
            "\n",
            "36100 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.623\n",
            "\n",
            "36200 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.651\n",
            "\n",
            "36300 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.604\n",
            "\n",
            "36400 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.490\n",
            "\n",
            "36500 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.638\n",
            "\n",
            "36600 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.991\n",
            "\n",
            "36700 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.822\n",
            "\n",
            "36800 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.612\n",
            "\n",
            "36900 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.737\n",
            "\n",
            "37000 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.643\n",
            "\n",
            "37100 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.446\n",
            "\n",
            "37200 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.831\n",
            "\n",
            "37300 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 71.323\n",
            "\n",
            "37400 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.965\n",
            "\n",
            "37500 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.742\n",
            "\n",
            "37600 iterations\n",
            "recon_error: 0.025\n",
            "perplexity: 70.253\n",
            "\n",
            "37700 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.269\n",
            "\n",
            "37800 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.881\n",
            "\n",
            "37900 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.725\n",
            "\n",
            "38000 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.777\n",
            "\n",
            "38100 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.439\n",
            "\n",
            "38200 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.945\n",
            "\n",
            "38300 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.837\n",
            "\n",
            "38400 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 71.152\n",
            "\n",
            "38500 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.406\n",
            "\n",
            "38600 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 71.118\n",
            "\n",
            "38700 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 71.090\n",
            "\n",
            "38800 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 70.504\n",
            "\n",
            "38900 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 71.437\n",
            "\n",
            "39000 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 71.075\n",
            "\n",
            "39100 iterations\n",
            "recon_error: 0.025\n",
            "perplexity: 71.538\n",
            "\n",
            "39200 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 71.461\n",
            "\n",
            "39300 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 71.068\n",
            "\n",
            "39400 iterations\n",
            "recon_error: 0.025\n",
            "perplexity: 71.277\n",
            "\n",
            "39500 iterations\n",
            "recon_error: 0.025\n",
            "perplexity: 70.928\n",
            "\n",
            "39600 iterations\n",
            "recon_error: 0.025\n",
            "perplexity: 71.213\n",
            "\n",
            "39700 iterations\n",
            "recon_error: 0.024\n",
            "perplexity: 69.923\n",
            "\n",
            "39800 iterations\n",
            "recon_error: 0.026\n",
            "perplexity: 71.692\n",
            "\n",
            "39900 iterations\n",
            "recon_error: 0.025\n",
            "perplexity: 71.171\n",
            "\n",
            "40000 iterations\n",
            "recon_error: 0.025\n",
            "perplexity: 71.064\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TANmRi0B9dSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reconstructions\n",
        "train_originals = get_images(sess, subset='train')['images']\n",
        "feed_dict = {x: train_originals}\n",
        "train_reconstructions = sess.run([x_recon_eval,indices,indices_old], feed_dict=feed_dict)\n",
        "sess.run(test_dataset_iterator.initializer)\n",
        "test_originals = get_images(sess, subset='test')['images']\n",
        "feed_dict = {x: test_originals}\n",
        "test_reconstructions = sess.run([x_recon_eval,indices,indices_old] ,feed_dict=feed_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CelxLqT99rL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_batch_to_image_grid(image_batch):\n",
        "  reshaped = (image_batch.reshape(4, 8, 28, 28, 1)\n",
        "              .transpose(0, 2, 1, 3, 4)\n",
        "              .reshape(4 * 28, 8 * 28, 1))\n",
        "  reshaped+=0.5\n",
        "  for i in range(reshaped.shape[0]):\n",
        "    for j in range(reshaped.shape[1]):\n",
        "      for k in range(reshaped.shape[2]):\n",
        "        if reshaped[i,j,k]>1:\n",
        "          reshaped[i,j,k]=1\n",
        "        elif reshaped[i,j,k]<0:\n",
        "          reshaped[i,j,k]=0        \n",
        "  return reshaped\n",
        "f = plt.figure(figsize=(16,8))\n",
        "ax = f.add_subplot(2,2,1)\n",
        "ax.imshow(np.resize(convert_batch_to_image_grid(train_originals), (112, 224)),\n",
        "          interpolation='nearest')\n",
        "ax.set_title('training data originals')\n",
        "plt.axis('off')\n",
        "\n",
        "ax = f.add_subplot(2,2,2)\n",
        "ax.imshow(np.resize(convert_batch_to_image_grid(train_reconstructions[0]),(112,224)),\n",
        "          interpolation='nearest')\n",
        "ax.set_title('training data reconstructions')\n",
        "plt.axis('off')\n",
        "\n",
        "ax = f.add_subplot(2,2,3)\n",
        "ax.imshow(np.resize(convert_batch_to_image_grid(test_originals), (112, 224)),\n",
        "          interpolation='nearest')\n",
        "ax.set_title('validation data originals')\n",
        "plt.axis('off')\n",
        "\n",
        "ax = f.add_subplot(2,2,4)\n",
        "ax.imshow(np.resize(convert_batch_to_image_grid(test_reconstructions[0]),(112,224)),\n",
        "          interpolation='nearest')\n",
        "ax.set_title('validation data reconstructions')\n",
        "plt.axis('off')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJhv-NNB4pJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install scipy\n",
        "import scipy.io as sio\n",
        "from google.colab import files\n",
        "sio.savemat('codebook.mat',{'codebook': results[3]})\n",
        "files.download('codebook.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDMxfzM_9yS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label=[]\n",
        "train_index=[]\n",
        "original = []\n",
        "for i in range(60000):\n",
        "  train_originals = get_images_classification(sess, subset='train')\n",
        "  feed_dict = {x: train_originals['images']}\n",
        "  train_labels = train_originals['labels']\n",
        "  train_reconstructions = sess.run([x_recon_eval,indices,z], feed_dict=feed_dict)\n",
        "  train_index.append(train_reconstructions[1][0])\n",
        "  original.append(train_reconstructions[2][0])\n",
        "  label.append(train_labels)\n",
        "sio.savemat('train_index.mat',{'train_index': train_index})\n",
        "files.download('train_index.mat')\n",
        "sio.savemat('label.mat',{'label': label})\n",
        "files.download('label.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOlu-IMn1IDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new=[]\n",
        "for i in range(40000):\n",
        "  for j in range(8):\n",
        "    for k in range(8):\n",
        "      new.append(original[i][j][k][:])\n",
        "      \n",
        "mapping=[]\n",
        "for i in range(40000):\n",
        "  for j in range(8):\n",
        "    for k in range(8):\n",
        "      mapping.append(results[3][:,train_index[i][j][k]])\n",
        "Install the PyDrive wrapper & import libraries.\n",
        "This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "import scipy.io as sio\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "# Create & upload a file.\n",
        "sio.savemat('new.mat',{'new': new})\n",
        "sio.savemat('mapping.mat', {'mapping': mapping})\n",
        "uploaded = drive.CreateFile({'title': 'new.mat'})\n",
        "uploaded.SetContentFile('new.mat')\n",
        "uploaded.Upload()\n",
        "uploaded1 = drive.CreateFile({'title': 'mapping.mat'})\n",
        "uploaded1.SetContentFile('mapping.mat')\n",
        "uploaded1.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57TSpQ2PH8qt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table = np.zeros([num_embeddings,num_embeddings])\n",
        "for j in range(num_embeddings):\n",
        "    for k in range(j+1,num_embeddings):\n",
        "        dis = 0\n",
        "        for i in range(embedding_dim):\n",
        "            table[j][k] += (results[3][i][j]-results[3][i][k]) ** 2\n",
        "        table[k][j] = table[j][k]\n",
        "sio.savemat('table.mat',{'table': table})\n",
        "files.download('table.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qneriZiR3-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_label=[]\n",
        "test_index=[]\n",
        "for i in range(10000):\n",
        "  test_originals = get_images_classification(sess, subset='test')\n",
        "  test_labels = test_originals['labels']\n",
        "  feed_dict = {x: test_originals['images']}\n",
        "  test_reconstructions = sess.run([x_recon_eval,indices] ,feed_dict=feed_dict)\n",
        "  test_index.append(test_reconstructions[1][0])\n",
        "  test_label.append(test_labels)\n",
        "sio.savemat('test_index.mat',{'test_index': test_index})\n",
        "files.download('test_index.mat')\n",
        "sio.savemat('test_label.mat',{'test_label': test_label})\n",
        "files.download('test_label.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}